# .lmconfig - Configuration file for LM user preferences

# Set the default API standard
api=openai

# Set the default model
model=gpt-4o

# Controls the randomness of the model's output
temperature=0.5

# Default prompt for instructing the model
instruct_prompt="Please provide a summary of the following text:"

# Default context to provide to the model
context="The context of this conversation is about AI and machine learning."

# Maximum number of tokens to generate
max_tokens=150

# Controls the diversity of the model's output
top_p=0.9

# Penalizes new tokens based on their existing frequency in the text
frequency_penalty=0.5

# Penalizes new tokens based on whether they appear in the text so far
presence_penalty=0.6
